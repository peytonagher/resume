{
  "metadata": {
    "mimir": {
      "data": {},
      "last_submission_id": "",
      "project_id": "3fb86145-c007-4378-b68f-ae3b9e29806d"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Introduction\n\n\nIn this homework you will implement a simple binary perceptron and train it to perform simple classification. This task involves classifying tumors as malignant or benign (0 and 1 respectively) according to 30 different measurements (features).",
      "metadata": {
        "state": "normal"
      }
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "state": "normal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Grading\n\n\n1. As long as your perceptron classifier (or the other classifiers other than a naive classifier, such as predicting the most frequent class label for all test cases) achieves an at least 70% accuracy and runs in less than three minutes you will get the full credit!\n2. If you classifier achieves more than 90% accuracy, you get 5 bonus points (20% of the full credit for Project 2).\n2. Please do not use sklearn or any off the shelf perceptron classifiers. \n3. We have a solution with less than 12 lines of code that gets over 94% accuracy. This is not a complicated/long coding assignment. \n4. Please make sure to document your code.\n",
      "metadata": {
        "state": "normal"
      }
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "state": "normal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Procedure\n\nThere are two phases for this project:\n1. getting and loading the dataset\n2. implementing, training and testing the perceptron.\n",
      "metadata": {
        "state": "normal",
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "state": "normal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Phase One: Packages, Data, and Setup\n\n\nThe package sklearn is a popular machine learning library for python. In addition to implementations of many algorithms and tools for  statistical analysis this package also contains many small datasets of anything. Please note you will not use that library for the perceptron algorithm --that is your task to implement. But you can use it for loading data, etc. \n",
      "metadata": {
        "state": "normal"
      }
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport sklearn\nfrom sklearn import datasets\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\nimport random",
      "metadata": {
        "state": "normal",
        "trusted": true
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "from sklearn.preprocessing import StandardScaler",
      "metadata": {
        "state": "normal",
        "trusted": true
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "state": "normal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Next we will import the data and split it to training and testing sets. The following lines load the UCI ML Breast Cancer Wisconsin (Diagnostic) Data Set. which contains 569 cases of tumors (each represented by 30 measurements). We split this data to 500 training cases and the rest for testing.",
      "metadata": {
        "state": "normal"
      }
    },
    {
      "cell_type": "code",
      "source": "# load the data set\nimg,label=sklearn.datasets.load_breast_cancer(return_X_y=True)\n# split the data set\nTRAIN_SIZE = 511\nlabel = 2*label-1\ntrain_img,test_img = img[:TRAIN_SIZE], img[TRAIN_SIZE:]\ntrain_label,test_label = label[:TRAIN_SIZE], label[TRAIN_SIZE:]",
      "metadata": {
        "state": "normal",
        "trusted": true
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "state": "normal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Phase Two: Perceptron Model",
      "metadata": {
        "state": "normal"
      }
    },
    {
      "cell_type": "code",
      "source": "# Perceptron Class\nclass Perceptron(object):\n    # Initialize the perceptron\n    def __init__(self, dim_input = 30, dim_out = 2, learning_rate = 1):\n        # model parameters \n        self.w = np.zeros(dim_input)\n        self.bias = 0.0\n        \n        # learning rate\n        self.learning_rate = learning_rate\n    \n    \n    def predict(self,input_array):\n        # See the \"Perceptron learning rule\" slides: w * x\n        # Calculate dot product of weights and the input array, add the bias\n        output = np.dot(self.w, input_array) + self.bias\n        # Apply the step function\n        return np.where(output >= 0, 1, -1)\n                    \n            \n    def train(self, training_inputs, labels):\n        for inputs, label in zip(training_inputs, labels):\n            prediction = self.predict(inputs)\n            # Update weights and bias\n            self.w += self.learning_rate * (label - prediction) * inputs\n            self.bias += self.learning_rate * (label - prediction)\n\n    \n    def test(self, testing_inputs, labels):\n        # number of correct predictions\n        count_correct = 0\n        # a list of the predicted labels the same order as the input \n        pred_list = []\n        for test_array, label in zip(testing_inputs,labels):\n            prediction = self.predict(test_array)\n            if prediction == label:\n                count_correct += 1\n            pred_list.append(prediction)\n        accuracy = float(count_correct)/len(test_label)\n        print('Accuracy is '+str(accuracy))\n        return np.asarray(pred_list)",
      "metadata": {
        "state": "normal",
        "trusted": true
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Feature scaling\nscaler = StandardScaler()\ntrain_img = scaler.fit_transform(train_img)\ntest_img = scaler.transform(test_img)\n\nnp.random.seed(42)",
      "metadata": {
        "state": "normal",
        "trusted": true
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Number of epochs (iterations over the training set)\nNUM_EPOCH = 500",
      "metadata": {
        "state": "normal",
        "trusted": true
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "perceptron = Perceptron(learning_rate=0.5)\nfor ii in range(NUM_EPOCH):\n    # Shuffle the training data\n    permutation = np.random.permutation(len(train_img))\n    train_img, train_label = train_img[permutation], train_label[permutation]\n    perceptron.train(train_img, train_label)\nprint(str(NUM_EPOCH)+' epochs')\npred_array = perceptron.test(test_img, test_label)",
      "metadata": {
        "state": "normal",
        "trusted": true
      },
      "execution_count": 21,
      "outputs": [
        {
          "name": "stdout",
          "text": "500 epochs\nAccuracy is 0.9827586206896551\n",
          "output_type": "stream"
        }
      ]
    }
  ]
}